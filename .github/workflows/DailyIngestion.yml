name: JavDB Daily Ingestion Pipeline

on:
  workflow_dispatch:
  schedule:
    # Run daily at 10:00 UTC (18:00 Beijing Time)
    - cron: '0 10 * * *'

jobs:
  # =============================================================================
  # Job 1: Setup - Checkout, install dependencies, generate config
  # =============================================================================
  setup:
    runs-on: ARM64
    environment: WT_DailyIngestion
    outputs:
      branch: ${{ steps.branch_check.outputs.branch }}
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          ssh-key: ${{ secrets.DEPLOY_KEY }}

      - name: Get current branch
        id: branch_check
        run: |
          CURRENT_BRANCH="${GITHUB_REF#refs/heads/}"
          echo "Current branch: $CURRENT_BRANCH"
          echo "branch=$CURRENT_BRANCH" >> $GITHUB_OUTPUT

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: pip install -r requirements.txt

      - name: Generate config.py from GitHub Variables and Secrets
        env:
          # ============ SECRETS (sensitive: passwords, tokens, IPs) ============
          VAR_QB_HOST: ${{ secrets.QB_HOST }}
          VAR_QB_PASSWORD: ${{ secrets.QB_PASSWORD }}
          VAR_SMTP_PASSWORD: ${{ secrets.SMTP_PASSWORD }}
          VAR_PROXY_POOL_JSON: ${{ secrets.PROXY_POOL_JSON }}
          VAR_JAVDB_PASSWORD: ${{ secrets.JAVDB_PASSWORD }}
          VAR_JAVDB_SESSION_COOKIE: ${{ secrets.JAVDB_SESSION_COOKIE }}
          VAR_PIKPAK_PASSWORD: ${{ secrets.PIKPAK_PASSWORD }}
          # ============ VARIABLES (non-sensitive) ============
          VAR_GIT_REPO_URL: ${{ vars.GIT_REPO_URL }}
          VAR_GIT_BRANCH: ${{ vars.GIT_BRANCH }}
          VAR_QB_PORT: ${{ vars.QB_PORT }}
          VAR_QB_USERNAME: ${{ vars.QB_USERNAME }}
          VAR_TORRENT_CATEGORY: ${{ vars.TORRENT_CATEGORY }}
          VAR_TORRENT_CATEGORY_ADHOC: ${{ vars.TORRENT_CATEGORY_ADHOC }}
          VAR_TORRENT_SAVE_PATH: ${{ vars.TORRENT_SAVE_PATH }}
          VAR_AUTO_START: ${{ vars.AUTO_START }}
          VAR_SKIP_CHECKING: ${{ vars.SKIP_CHECKING }}
          VAR_REQUEST_TIMEOUT: ${{ vars.REQUEST_TIMEOUT }}
          VAR_DELAY_BETWEEN_ADDITIONS: ${{ vars.DELAY_BETWEEN_ADDITIONS }}
          VAR_SMTP_SERVER: ${{ vars.SMTP_SERVER }}
          VAR_SMTP_PORT: ${{ vars.SMTP_PORT }}
          VAR_SMTP_USER: ${{ vars.SMTP_USER }}
          VAR_EMAIL_FROM: ${{ vars.EMAIL_FROM }}
          VAR_EMAIL_TO: ${{ vars.EMAIL_TO }}
          VAR_PROXY_MODE: ${{ vars.PROXY_MODE }}
          VAR_PROXY_POOL_COOLDOWN_SECONDS: ${{ vars.PROXY_POOL_COOLDOWN_SECONDS }}
          VAR_PROXY_POOL_MAX_FAILURES: ${{ vars.PROXY_POOL_MAX_FAILURES }}
          VAR_PROXY_MODULES_JSON: ${{ vars.PROXY_MODULES_JSON }}
          VAR_CF_BYPASS_SERVICE_PORT: ${{ vars.CF_BYPASS_SERVICE_PORT }}
          VAR_CF_BYPASS_ENABLED: ${{ vars.CF_BYPASS_ENABLED }}
          VAR_START_PAGE: ${{ vars.START_PAGE }}
          VAR_END_PAGE: ${{ vars.END_PAGE }}
          VAR_PHASE2_MIN_RATE: ${{ vars.PHASE2_MIN_RATE }}
          VAR_PHASE2_MIN_COMMENTS: ${{ vars.PHASE2_MIN_COMMENTS }}
          VAR_BASE_URL: ${{ vars.BASE_URL }}
          VAR_JAVDB_USERNAME: ${{ vars.JAVDB_USERNAME }}
          VAR_DETAIL_PAGE_SLEEP: ${{ vars.DETAIL_PAGE_SLEEP }}
          VAR_PAGE_SLEEP: ${{ vars.PAGE_SLEEP }}
          VAR_MOVIE_SLEEP: ${{ vars.MOVIE_SLEEP }}
          VAR_CF_TURNSTILE_COOLDOWN: ${{ vars.CF_TURNSTILE_COOLDOWN }}
          VAR_PHASE_TRANSITION_COOLDOWN: ${{ vars.PHASE_TRANSITION_COOLDOWN }}
          VAR_FALLBACK_COOLDOWN: ${{ vars.FALLBACK_COOLDOWN }}
          VAR_LOG_LEVEL: ${{ vars.LOG_LEVEL }}
          VAR_SPIDER_LOG_FILE: ${{ vars.SPIDER_LOG_FILE }}
          VAR_UPLOADER_LOG_FILE: ${{ vars.UPLOADER_LOG_FILE }}
          VAR_PIPELINE_LOG_FILE: ${{ vars.PIPELINE_LOG_FILE }}
          VAR_EMAIL_NOTIFICATION_LOG_FILE: ${{ vars.EMAIL_NOTIFICATION_LOG_FILE }}
          VAR_IGNORE_RELEASE_DATE_FILTER: ${{ vars.IGNORE_RELEASE_DATE_FILTER }}
          VAR_DAILY_REPORT_DIR: ${{ vars.DAILY_REPORT_DIR }}
          VAR_AD_HOC_DIR: ${{ vars.AD_HOC_DIR }}
          VAR_PARSED_MOVIES_CSV: ${{ vars.PARSED_MOVIES_CSV }}
          VAR_PIKPAK_EMAIL: ${{ vars.PIKPAK_EMAIL }}
          VAR_PIKPAK_LOG_FILE: ${{ vars.PIKPAK_LOG_FILE }}
          VAR_PIKPAK_REQUEST_DELAY: ${{ vars.PIKPAK_REQUEST_DELAY }}
        run: python3 utils/config_generator.py --github-actions

      - name: Pull latest changes from remote
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          CURRENT_BRANCH="${{ steps.branch_check.outputs.branch }}"
          echo "Pulling latest changes from branch: $CURRENT_BRANCH"
          
          REPO_URL=$(git remote get-url origin)
          if [[ "$REPO_URL" == https://* ]]; then
            REPO_SSH=$(echo "$REPO_URL" | sed 's|https://github.com/|git@github.com:|')
            git remote set-url origin "$REPO_SSH"
            echo "Updated remote URL to SSH: $REPO_SSH"
          fi
          
          git fetch origin "$CURRENT_BRANCH"
          git pull --rebase origin "$CURRENT_BRANCH" || {
            echo "Warning: Failed to pull/rebase, attempting merge instead"
            git pull --no-edit origin "$CURRENT_BRANCH" || {
              echo "Error: Could not integrate remote changes"
              exit 1
            }
          }

      - name: Upload config artifact
        uses: actions/upload-artifact@v4
        with:
          name: config
          path: config.py
          retention-days: 1

  # =============================================================================
  # Job 2: Health Check - Verify essential services before running pipeline
  # =============================================================================
  health-check:
    runs-on: ARM64
    environment: WT_DailyIngestion
    needs: setup
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: pip install -r requirements.txt

      - name: Download config
        uses: actions/download-artifact@v4
        with:
          name: config
          path: .

      - name: Run health checks
        run: python3 scripts/health_check.py --use-proxy

  # =============================================================================
  # Job 3: Run Pipeline - Execute spider, uploader, and pikpak bridge
  # =============================================================================
  run-pipeline:
    runs-on: ARM64
    environment: WT_DailyIngestion
    needs: [setup, health-check]
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          ssh-key: ${{ secrets.DEPLOY_KEY }}

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: pip install -r requirements.txt

      - name: Download config
        uses: actions/download-artifact@v4
        with:
          name: config
          path: .

      - name: Pull latest changes
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          CURRENT_BRANCH="${{ needs.setup.outputs.branch }}"
          
          REPO_URL=$(git remote get-url origin)
          if [[ "$REPO_URL" == https://* ]]; then
            REPO_SSH=$(echo "$REPO_URL" | sed 's|https://github.com/|git@github.com:|')
            git remote set-url origin "$REPO_SSH"
          fi
          
          git fetch origin "$CURRENT_BRANCH"
          git pull --rebase origin "$CURRENT_BRANCH" || git pull --no-edit origin "$CURRENT_BRANCH" || true

      - name: Step 1 - Run Spider
        id: spider
        run: python3 scripts/spider.py --use-proxy

      - name: Step 2 - Run qBittorrent Uploader
        id: uploader
        run: python3 scripts/qb_uploader.py --mode daily --use-proxy

      - name: Step 3 - Run PikPak Bridge
        id: pikpak
        run: python3 scripts/pikpak_bridge.py --days 3

      - name: Upload logs artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: pipeline-logs
          path: |
            logs/*.log
          retention-days: 7

      - name: Upload CSV reports artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: pipeline-reports
          path: |
            Daily Report/*.csv
            Ad Hoc/*.csv
          retention-days: 7

  # =============================================================================
  # Job 4: Email Notification - Always runs to report success or failure
  # =============================================================================
  email-notification:
    runs-on: ARM64
    environment: WT_DailyIngestion
    needs: [setup, health-check, run-pipeline]
    if: always()
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: pip install -r requirements.txt

      - name: Download config
        uses: actions/download-artifact@v4
        with:
          name: config
          path: .

      - name: Download logs (if available)
        uses: actions/download-artifact@v4
        with:
          name: pipeline-logs
          path: logs
        continue-on-error: true

      - name: Download reports (if available)
        uses: actions/download-artifact@v4
        with:
          name: pipeline-reports
          path: .
        continue-on-error: true

      - name: Determine pipeline status
        id: status
        run: |
          # Check the status of all previous jobs
          SETUP_STATUS="${{ needs.setup.result }}"
          HEALTH_STATUS="${{ needs.health-check.result }}"
          PIPELINE_STATUS="${{ needs.run-pipeline.result }}"
          
          echo "Setup: $SETUP_STATUS"
          echo "Health Check: $HEALTH_STATUS"
          echo "Pipeline: $PIPELINE_STATUS"
          
          # Create a status file for email notification to read
          echo "SETUP_STATUS=$SETUP_STATUS" >> logs/job_status.txt
          echo "HEALTH_CHECK_STATUS=$HEALTH_STATUS" >> logs/job_status.txt
          echo "PIPELINE_STATUS=$PIPELINE_STATUS" >> logs/job_status.txt
          
          if [[ "$SETUP_STATUS" == "failure" ]] || [[ "$HEALTH_STATUS" == "failure" ]] || [[ "$PIPELINE_STATUS" == "failure" ]]; then
            echo "has_failure=true" >> $GITHUB_OUTPUT
            echo "Pipeline had failures"
          else
            echo "has_failure=false" >> $GITHUB_OUTPUT
            echo "Pipeline completed successfully"
          fi

      - name: Run Email Notification
        env:
          PIPELINE_HAS_FAILURE: ${{ steps.status.outputs.has_failure }}
        run: python3 scripts/email_notification.py

  # =============================================================================
  # Job 5: Commit Results - Commit CSV files only (no logs)
  # =============================================================================
  commit-results:
    runs-on: ARM64
    environment: WT_DailyIngestion
    needs: [setup, run-pipeline, email-notification]
    if: always() && needs.run-pipeline.result != 'skipped'
    permissions:
      contents: write
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          ssh-key: ${{ secrets.DEPLOY_KEY }}

      - name: Download reports
        uses: actions/download-artifact@v4
        with:
          name: pipeline-reports
          path: .
        continue-on-error: true

      - name: Commit and Push Results
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          
          CURRENT_BRANCH="${{ needs.setup.outputs.branch }}"
          echo "Pushing to branch: $CURRENT_BRANCH"
          
          REPO_URL=$(git remote get-url origin)
          if [[ "$REPO_URL" == https://* ]]; then
            REPO_SSH=$(echo "$REPO_URL" | sed 's|https://github.com/|git@github.com:|')
            git remote set-url origin "$REPO_SSH"
            echo "Updated remote URL to SSH: $REPO_SSH"
          fi
          
          git fetch origin "$CURRENT_BRANCH"
          if git rev-parse --verify "origin/$CURRENT_BRANCH" >/dev/null 2>&1; then
            LOCAL=$(git rev-parse HEAD)
            REMOTE=$(git rev-parse "origin/$CURRENT_BRANCH")
            if [ "$LOCAL" != "$REMOTE" ]; then
              echo "Remote has new commits, pulling with autostash..."
              git pull --rebase --autostash origin "$CURRENT_BRANCH" || git pull --no-edit --autostash origin "$CURRENT_BRANCH" || true
            fi
          fi
          
          # Add CSV files only (no logs)
          git add 'Daily Report'/*.csv || true
          git add 'Ad Hoc'/*.csv || true
          
          # Check if there are any changes to commit
          if git diff --cached --quiet; then
            echo "No changes to commit"
          else
            git commit -m "Auto-commit: Daily pipeline results $(date +'%Y-%m-%d %H:%M:%S UTC')"
            git push origin "$CURRENT_BRANCH"
            echo "âœ“ Changes committed and pushed to $CURRENT_BRANCH branch successfully"
          fi
